{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    ">In this notebook you'll work through the end to end machine learning pipeline and score in the top 1% of all participants in the Kaggle competition. \n",
    "\n",
    "Kaggle is a site that hosts competitive modeling competitions. In the applied space, a score in the top 5% of this competition is considered a resume worthy bullet point. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you'll need for this project\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost** is an open source machine learning library that belongs to a class of models called gradient boosters. XGBoost is a supervised machine learning algorithm.  Supervised learning models use existing data to look for patterns.  Two of the most common approaches used when building supervised learning models are classification and regression. XGBoost excels at building highly accurate classification and regression models very quickly.  This means that XGBoost is a top choice for building real world models against highly structured datasets. XGBoost has also become the gold standard for competitive modeling. \n",
    "\n",
    "> XGBoost has won almost every competition using structured datasets on Kaggle and other competitive modeling competitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a variable called data to hold the titanic dataset\n",
    "data = pd.read_csv(\"titanic.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary**\n",
    "\n",
    "\n",
    "- [survived] Survival 0 = No, 1 = Yes (This is the target variable)\n",
    "- [pclass] Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- [sex] Sex \n",
    "- [Age] Age in years \n",
    "- [sibsp] # of siblings / spouses aboard the Titanic \n",
    "- [parch] # of parents / children aboard the Titanic \n",
    "- [ticket] Ticket number \n",
    "- [fare] Passenger fare \n",
    "- [cabin] Cabin number \n",
    "- [embarked] Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell let's view the percentage of those who died versus those who survived. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries I need for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plot survived vs dies\n",
    "f,ax=plt.subplots(1,2,figsize=(19,8))\n",
    "data['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "ax[0].set_title('Survived')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Survived',data=data,ax=ax[1])\n",
    "ax[1].set_title('Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not many survived this tradgedy. Out of 891 passengers in training set, only around 350 survived. \n",
    "\n",
    "> Only **38.4%** of the total training set survived the crash.  \n",
    "\n",
    "Let’s craft a graph to view the survivors based on their genders. Spoiler alert. The men didn’t too well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a bar plot of survival by sex\n",
    "sns.barplot(x=\"Sex\", y=\"Survived\", data=data)\n",
    "\n",
    "#print percentages of females vs. males that survive\n",
    "print(\"Percentage of females who survived:\", data[\"Survived\"][data[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of males who survived:\", data[\"Survived\"][data[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called data to hold only the attributes we want. \n",
    "data = data [['Survived', 'Pclass', 'Sex','Age','SibSp','Parch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After I view the dataset the only non-numeric attribute is sex\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use label encoding to covert sex to numbers\n",
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "data['Sex']= label_encoder.fit_transform(data['Sex']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how many null values are in the dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below I've chosen to drop all the NAN values instead of replacing them. \n",
    "\n",
    "> I did use mean value imputation, however, the model's performance was not as good as just dropping them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the NANs in the age attribute\n",
    "data.dropna(subset=['Age'], how='all', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and Y. \n",
    "X = data.drop('Survived', axis=1)\n",
    "# The target variable is Survived. \n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below I'm using train/test/split to create training and testing sets. The random_state parameter is used for reproducability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into disparate training and testing splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier. All models in SciKit-Learn are called classifiers. \n",
    "# I'm using the SciKit-Learn implementation of XGBoost on this project.\n",
    "model = XGBClassifier(max_depth=4,n_estimators=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's create a variable to hold our prediction against test dataset and make predictions.\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing metrics and using accuracy as the metric for this project\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
